{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v3I9nBhs-wE"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2d-su7is-wG"
      },
      "source": [
        "# GraphRAG Implementation with LlamaIndex\n",
        "\n",
        "[GraphRAG (Graphs + Retrieval Augmented Generation)](https://www.microsoft.com/en-us/research/project/graphrag/) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
        "\n",
        "\n",
        "This notebook provides guidance on constructing the GraphRAG pipeline using the LlamaIndex PropertyGraph abstractions.\n",
        "\n",
        "\n",
        "**NOTE:** This is an approximate implementation of GraphRAG. We are currently developing a series of cookbooks that will detail the exact implementation of GraphRAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMweJAnSs-wH"
      },
      "source": [
        "## GraphRAG Aproach\n",
        "\n",
        "The GraphRAG involves two steps:\n",
        "\n",
        "1. Graph Generation - Creates Graph, builds communities and its summaries over the given document.\n",
        "2. Answer to the Query - Use summaries of the communities created from step-1 to answer the query.\n",
        "\n",
        "**Graph Generation:**\n",
        "\n",
        "1. **Source Documents to Text Chunks:** Source documents are divided into smaller text chunks for easier processing.\n",
        "\n",
        "2. **Text Chunks to Element Instances:** Each text chunk is analyzed to identify and extract entities and relationships, resulting in a list of tuples that represent these elements.\n",
        "\n",
        "3. **Element Instances to Element Summaries:** The extracted entities and relationships are summarized into descriptive text blocks for each element using the LLM.\n",
        "\n",
        "4. **Element Summaries to Graph Communities:** These entities, relationships and summaries form a graph, which is subsequently partitioned into communities using algorithms using Heirarchical Leiden to establish a hierarchical structure.\n",
        "\n",
        "5. **Graph Communities to Community Summaries:** The LLM generates summaries for each community, providing insights into the dataset’s overall topical structure and semantics.\n",
        "\n",
        "**Answering the Query:**\n",
        "\n",
        "**Community Summaries to Global Answers:** The summaries of the communities are utilized to respond to user queries. This involves generating intermediate answers, which are then consolidated into a comprehensive global answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEl71Dzvs-wH"
      },
      "source": [
        "## GraphRAG Pipeline Components\n",
        "\n",
        "Here are the different components we implemented to build all of the processes mentioned above.\n",
        "\n",
        "1. **Source Documents to Text Chunks:** Implemented using `SentenceSplitter` with a chunk size of 1024 and chunk overlap of 20 tokens.\n",
        "\n",
        "2. **Text Chunks to Element Instances AND Element Instances to Element Summaries:** Implemented using `GraphRAGExtractor`.\n",
        "\n",
        "3. **Element Summaries to Graph Communities AND Graph Communities to Community Summaries:** Implemented using `GraphRAGStore`.\n",
        "\n",
        "4. **Community Summaries to Global Answers:** Implemented using `GraphQueryEngine`.\n",
        "\n",
        "\n",
        "Let's check into each of these components and build GraphRAG pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySzCypGs-wH"
      },
      "source": [
        "## Installation\n",
        "\n",
        "`graspologic` is used to use hierarchical_leiden for building communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BQ2GElx-s-wH",
        "outputId": "be8313c1-8c47-4177-de1b-5fdf023b0321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.35)\n",
            "Requirement already satisfied: graspologic in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Collecting numpy==2.0.0\n",
            "  Using cached numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scipy==1.13.0\n",
            "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.35 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.35)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.38)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: anytree>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (2.13.0)\n",
            "Requirement already satisfied: beartype>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.20.2)\n",
            "Requirement already satisfied: gensim!=4.2.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (4.3.2)\n",
            "Requirement already satisfied: graspologic-native>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from graspologic) (1.2.5)\n",
            "Requirement already satisfied: hyppo>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (1.4.2)\n",
            "Requirement already satisfied: matplotlib!=3.3.*,!=3.6.1,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (3.8.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from graspologic) (3.4.2)\n",
            "Requirement already satisfied: POT>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.9.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (1.6.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.14.4)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from graspologic) (4.13.2)\n",
            "Requirement already satisfied: umap-learn>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from graspologic) (0.5.7)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim!=4.2.0,>=4.0.0->graspologic) (7.1.0)\n",
            "Requirement already satisfied: numba>=0.46 in /usr/local/lib/python3.11/dist-packages (from hyppo>=0.3.2->graspologic) (0.60.0)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.11/dist-packages (from hyppo>=0.3.2->graspologic) (1.7.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.76.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.11.4)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.35->llama-index) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.19)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.5.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->graspologic) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->graspologic) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.4.6->graspologic) (0.5.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.20.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.35->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.35->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.35->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.35->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.22 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.46->hyppo>=0.3.2->graspologic) (0.43.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.35->llama-index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.35->llama-index) (3.2.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.35->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.0.2)\n",
            "Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.0\n",
            "    Uninstalling numpy-1.26.0:\n",
            "      Successfully uninstalled numpy-1.26.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.12.0\n",
            "    Uninstalling scipy-1.12.0:\n",
            "      Successfully uninstalled scipy-1.12.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.0\n",
            "    Uninstalling pandas-2.2.0:\n",
            "      Successfully uninstalled pandas-2.2.0\n",
            "Successfully installed numpy-2.0.0 pandas-2.2.2 scipy-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index graspologic numpy==2.0.0 pandas==2.2.2 scipy==1.13.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZsxHJls-wI"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "We will use a sample news article dataset retrieved from Diffbot, which Tomaz has conveniently made available on GitHub for easy access.\n",
        "\n",
        "The dataset contains 2,500 samples; for ease of experimentation, we will use 50 of these samples, which include the `title` and `text` of news articles."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.2.2"
      ],
      "metadata": {
        "id": "BObUjiyOuN0W",
        "outputId": "dbfa590b-4398-48a5-baf2-2a17a32d16d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "Successfully installed pandas-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yH7vlYIes-wI",
        "outputId": "5e332471-f381-457d-b540-fc610785a570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0                             Chevron: Best Of Breed   \n",
              "1       FirstEnergy (NYSE:FE) Posts Earnings Results   \n",
              "2  Dáil almost suspended after Sinn Féin TD put p...   \n",
              "3  Epic’s latest tool can animate hyperrealistic ...   \n",
              "4  EU to Ban Huawei, ZTE from Internal Commission...   \n",
              "\n",
              "                                  date  \\\n",
              "0  2031-04-06T01:36:32.000000000+00:00   \n",
              "1  2030-04-29T06:55:28.000000000+00:00   \n",
              "2  2023-06-15T14:32:11.000000000+00:00   \n",
              "3  2023-06-15T14:00:00.000000000+00:00   \n",
              "4  2023-06-15T13:50:00.000000000+00:00   \n",
              "\n",
              "                                                text  \n",
              "0  JHVEPhoto Like many companies in the O&G secto...  \n",
              "1  FirstEnergy (NYSE:FE – Get Rating) posted its ...  \n",
              "2  The Dáil was almost suspended on Thursday afte...  \n",
              "3  Today, Epic is releasing a new tool designed t...  \n",
              "4  The European Commission is planning to ban equ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d338ac7-aa52-4958-89d0-89ee37c8eb05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chevron: Best Of Breed</td>\n",
              "      <td>2031-04-06T01:36:32.000000000+00:00</td>\n",
              "      <td>JHVEPhoto Like many companies in the O&amp;G secto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FirstEnergy (NYSE:FE) Posts Earnings Results</td>\n",
              "      <td>2030-04-29T06:55:28.000000000+00:00</td>\n",
              "      <td>FirstEnergy (NYSE:FE – Get Rating) posted its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dáil almost suspended after Sinn Féin TD put p...</td>\n",
              "      <td>2023-06-15T14:32:11.000000000+00:00</td>\n",
              "      <td>The Dáil was almost suspended on Thursday afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Epic’s latest tool can animate hyperrealistic ...</td>\n",
              "      <td>2023-06-15T14:00:00.000000000+00:00</td>\n",
              "      <td>Today, Epic is releasing a new tool designed t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EU to Ban Huawei, ZTE from Internal Commission...</td>\n",
              "      <td>2023-06-15T13:50:00.000000000+00:00</td>\n",
              "      <td>The European Commission is planning to ban equ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d338ac7-aa52-4958-89d0-89ee37c8eb05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d338ac7-aa52-4958-89d0-89ee37c8eb05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d338ac7-aa52-4958-89d0-89ee37c8eb05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7c5c8d47-b9d1-4590-a044-08571cff52f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c5c8d47-b9d1-4590-a044-08571cff52f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7c5c8d47-b9d1-4590-a044-08571cff52f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news",
              "summary": "{\n  \"name\": \"news\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"NFL Rumors: What Patriots \\u2018Made Clear\\u2019 To DeAndre Hopkins\\u2019 Reps\",\n          \"Stellantis to close Illinois assembly plant, lay off workers\",\n          \"Uber to shut food delivery business in Italy, exit Israel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"2023-06-15T12:14:00.000000000+00:00\",\n          \"2023-06-15T12:11:00.000000000+00:00\",\n          \"2023-06-15T13:50:00.000000000+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"The Patriots apparently didn\\u2019t waste any time courting DeAndre Hopkins once he hit the open market.\\nHopkins officially became an NFL free agent when he was released by the Arizona Cardinals on May 26. Around that juncture, New England reportedly reached out to the star wide receiver\\u2019s team to express interest. Those conversations birthed a free-agent visit, which reportedly started Wednesday in Foxboro, Mass. and carried into Thursday morning.\\n\\u201cI just got official word: DeAndre Hopkins is in New England,\\u201d NFL insider Jeremy Fowler said Thursday on ESPN\\u2019s \\u201cGet Up.\\u201d \\u201cHe\\u2019s meeting with the Patriots. He will meet with the coaches, Bill Belichick. The Patriots\\u2019 interest remains high. They made that clear with Hopkins\\u2019 representatives from the very beginning when he became a free agent. So, we\\u2019ll see if they can close on this thing.\\u201d\\nHopkins has received co-signs from New England team leaders like Mac Jones and Matthew Judon, and the Patriots reportedly are optimistic they can add the five-time Pro Bowl selection. But even if Hopkins\\u2019 meeting with the Patriots goes well, don\\u2019t be surprised if the 31-year-old leaves New England without a deal.\\n\\u201cI\\u2019m also told Hopkins (is) not in a major rush,\\u201d Fowler said. \\u201cHe\\u2019s looking at more of training camp, even early August as more of a harder deadline for him to sign somewhere. So, it would have to be a very sweet offer for New England to make that happen today.\\u201d\\nThe Patriots appear to be the second team Hopkins met with as a free agent. Prior to his trip to New England, the veteran pass-catcher talked shop with the Titans in Nashville.\",\n          \"Generation Investment Management, an investment management firm, released its \\u201cGlobal Equity Strategy\\u201d first quarter 2023 investor letter. A copy of the same can be downloaded here. The strategy performed roughly in line with the benchmark on a rolling five-year net basis and it is about 1.3% below on a rolling three-year net basis. The main reasons for the underperformance of the strategy were overestimation of the quality of the holdings, change in the external environment, and overpayment for some companies. In addition, you can check the top 5 holdings of the fund to know its best picks in 2023.\\nGeneration Investment Management Global Equity Strategy highlighted stocks like Henry Schein, Inc. (NASDAQ:HSIC) in the first quarter 2023 investor letter. Headquartered in Melville, New York, Henry Schein, Inc. (NASDAQ:HSIC) is a healthcare products and services provider to medical, dental, and veterinary office-based practitioners. On June 14, 2023, Henry Schein, Inc. (NASDAQ:HSIC) stock closed at $74.81 per share. One-month return of Henry Schein, Inc. (NASDAQ:HSIC) was -2.27%, and its shares gained 2.24% of their value over the last 52 weeks. Henry Schein, Inc. (NASDAQ:HSIC) has a market capitalization of $9.8 billion.\\nGeneration Investment Management Global Equity Strategy made the following comment about Henry Schein, Inc. (NASDAQ:HSIC) in its first quarter 2023 investor letter:\\n\\\"We continue to evaluate new investment opportunities. Despite the volatility of recent months, we see a number of strong tailwinds in certain sectors \\u2014 particularly those that solve big societal problems. One such problem is growing healthcare costs, which will put more pressure on social-security systems and household budgets. Later in this letter we profile Henry Schein, Inc. (NASDAQ:HSIC), the largest distributor of dental and medical products and services globally. Companies like Henry Schein have the potential to control the growth in healthcare costs, while promoting access to underserved communities.\\nAt the same time, healthcare cost pressures are escalating. To make matters worse, healthcare has worse labour shortages than most industries, while productivity improvements are hard to come by.4 In almost every country, health spending is forecast to form an increasing share of GDP in the coming years.\\nAt Generation, we look for companies that can provide a solution to these long-term challenges. More specifically, we look for healthcare companies that reduce costs and drive efficiency; that improve clinical outcomes; and that improve access to care. Henry Schein, a long-term holding of your portfolio, is an example of a company that we believe can deliver on all three of these criteria...\\\" (Click here to read the full text)\\nHenry Schein, Inc. (NASDAQ:HSIC) is not on our list of . As per our database, 28 hedge fund portfolios held Henry Schein, Inc. (NASDAQ:HSIC) at the end of first quarter 2023 which was 30 in the previous quarter.\\nWe discussed Henry Schein, Inc. (NASDAQ:HSIC) in and shared the list of top gainers on November 1, 2022. In addition, please check out our page for more investor letters from hedge funds and other leading investors.\\nDisclosure: None. This article is originally published at .\",\n          \"Manchester City will begin their bid for a record fourth consecutive Premier League title away to Vincent Kompany\\u2019s Burnley.\\nThe Treble winners will visit Turf Moor to face their former captain\\u2019s newly-promoted side on the evening of Friday, August 11 to raise the curtain on the 2023-24 campaign.\\nIt will be the second time Kompany \\u2013 who won the title on four occasions as City skipper \\u2013 will have faced his old side as a manager, with City running out 6-0 winners at the Etihad in March\\u2019s FA Cup quarter-final.\\nPremier League debutants Luton will play their first top-flight fixture since 1992 away to Roberto De Zerbi\\u2019s Brighton on Saturday, August 12, having to wait until the following weekend for their first home game when Kenilworth Road will become the smallest ground to host a fixture in the competition for the visit of Burnley.\\nThe other promoted side Sheffield United kick off their season with a home game against Crystal Palace.\\nThe outstanding fixture of the opening weekend will be at Stamford Bridge where Mauricio Pochettino begins life as Chelsea manager against Liverpool on Sunday, August 13, with both sides looking to bounce back after disappointing campaigns.\\nFollow live updates and reaction below\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from llama_index.core import Document\n",
        "\n",
        "# Monkey-patch to bypass the error\n",
        "if not hasattr(pd.Index, '_format_flat'):\n",
        "    pd.Index._format_flat = lambda self, *args, **kwargs: self\n",
        "\n",
        "# Rest of your code remains the same\n",
        "news = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\"\n",
        ")[:50]\n",
        "\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCJ41-xjs-wJ"
      },
      "source": [
        "Prepare documents as required by LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WNHjKMris-wJ"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    Document(text=f\"{row['title']}: {row['text']}\")\n",
        "    for i, row in news.iterrows()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ5AGRhOs-wJ"
      },
      "source": [
        "## Setup API Key and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WivpMmjKs-wJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuBKqLsys-wK"
      },
      "source": [
        "## GraphRAGExtractor\n",
        "\n",
        "The GraphRAGExtractor class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
        "\n",
        "This functionality is similar to that of the `SimpleLLMPathExtractor`, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing [extractors](https://docs.llamaindex.ai/en/latest/examples/property_graph/Dynamic_KG_Extraction/?h=comparing).\n",
        "\n",
        "Here's a breakdown of its functionality:\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "1. `llm:` The language model used for extraction.\n",
        "2. `extract_prompt:` A prompt template used to guide the LLM in extracting information.\n",
        "3. `parse_fn:` A function to parse the LLM's output into structured data.\n",
        "4. `max_paths_per_chunk:` Limits the number of triples extracted per text chunk.\n",
        "5. `num_workers:` For parallel processing of multiple text nodes.\n",
        "\n",
        "\n",
        "**Main Methods:**\n",
        "\n",
        "1. `__call__:` The entry point for processing a list of text nodes.\n",
        "2. `acall:` An asynchronous version of __call__ for improved performance.\n",
        "3. `_aextract:` The core method that processes each individual node.\n",
        "\n",
        "\n",
        "**Extraction Process:**\n",
        "\n",
        "For each input node (chunk of text):\n",
        "1. It sends the text to the LLM along with the extraction prompt.\n",
        "2. The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
        "3. Entities are converted into EntityNode objects. Entity description is stored in metadata\n",
        "4. Relationships are converted into Relation objects. Relationship description is stored in metadata.\n",
        "5. These are added to the node's metadata under KG_NODES_KEY and KG_RELATIONS_KEY.\n",
        "\n",
        "**NOTE:** In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hOqQQUD9s-wK"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from typing import Any, List, Callable, Optional, Union, Dict\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from llama_index.core.async_utils import run_jobs\n",
        "from llama_index.core.indices.property_graph.utils import (\n",
        "    default_parse_triplets_fn,\n",
        ")\n",
        "from llama_index.core.graph_stores.types import (\n",
        "    EntityNode,\n",
        "    KG_NODES_KEY,\n",
        "    KG_RELATIONS_KEY,\n",
        "    Relation,\n",
        ")\n",
        "from llama_index.core.llms.llm import LLM\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.prompts.default_prompts import (\n",
        "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
        ")\n",
        "from llama_index.core.schema import TransformComponent, BaseNode\n",
        "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class GraphRAGExtractor(TransformComponent):\n",
        "    \"\"\"Extract triples from a graph.\n",
        "\n",
        "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
        "\n",
        "    Args:\n",
        "        llm (LLM):\n",
        "            The language model to use.\n",
        "        extract_prompt (Union[str, PromptTemplate]):\n",
        "            The prompt to use for extracting triples.\n",
        "        parse_fn (callable):\n",
        "            A function to parse the output of the language model.\n",
        "        num_workers (int):\n",
        "            The number of workers to use for parallel processing.\n",
        "        max_paths_per_chunk (int):\n",
        "            The maximum number of paths to extract per chunk.\n",
        "    \"\"\"\n",
        "\n",
        "    llm: LLM\n",
        "    extract_prompt: PromptTemplate\n",
        "    parse_fn: Callable\n",
        "    num_workers: int\n",
        "    max_paths_per_chunk: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm: Optional[LLM] = None,\n",
        "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
        "        parse_fn: Callable = default_parse_triplets_fn,\n",
        "        max_paths_per_chunk: int = 10,\n",
        "        num_workers: int = 4,\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        from llama_index.core import Settings\n",
        "\n",
        "        if isinstance(extract_prompt, str):\n",
        "            extract_prompt = PromptTemplate(extract_prompt)\n",
        "\n",
        "        super().__init__(\n",
        "            llm=llm or Settings.llm,\n",
        "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
        "            parse_fn=parse_fn,\n",
        "            num_workers=num_workers,\n",
        "            max_paths_per_chunk=max_paths_per_chunk,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def class_name(cls) -> str:\n",
        "        return \"GraphExtractor\"\n",
        "\n",
        "    def __call__(\n",
        "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
        "    ) -> List[BaseNode]:\n",
        "        \"\"\"Extract triples from nodes.\"\"\"\n",
        "        return asyncio.run(\n",
        "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
        "        )\n",
        "\n",
        "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
        "        \"\"\"Extract triples from a node.\"\"\"\n",
        "        assert hasattr(node, \"text\")\n",
        "\n",
        "        text = node.get_content(metadata_mode=\"llm\")\n",
        "        try:\n",
        "            llm_response = await self.llm.apredict(\n",
        "                self.extract_prompt,\n",
        "                text=text,\n",
        "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
        "            )\n",
        "            entities, entities_relationship = self.parse_fn(llm_response)\n",
        "        except ValueError:\n",
        "            entities = []\n",
        "            entities_relationship = []\n",
        "\n",
        "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
        "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
        "        metadata = node.metadata.copy()\n",
        "        for entity, entity_type, description in entities:\n",
        "            metadata[\n",
        "                \"entity_description\"\n",
        "            ] = description  # Not used in the current implementation. But will be useful in future work.\n",
        "            entity_node = EntityNode(\n",
        "                name=entity, label=entity_type, properties=metadata\n",
        "            )\n",
        "            existing_nodes.append(entity_node)\n",
        "\n",
        "        metadata = node.metadata.copy()\n",
        "        for triple in entities_relationship:\n",
        "            subj, obj, rel, description = triple\n",
        "            subj_node = EntityNode(name=subj, properties=metadata)\n",
        "            obj_node = EntityNode(name=obj, properties=metadata)\n",
        "            metadata[\"relationship_description\"] = description\n",
        "            rel_node = Relation(\n",
        "                label=rel,\n",
        "                source_id=subj_node.id,\n",
        "                target_id=obj_node.id,\n",
        "                properties=metadata,\n",
        "            )\n",
        "\n",
        "            existing_nodes.extend([subj_node, obj_node])\n",
        "            existing_relations.append(rel_node)\n",
        "\n",
        "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
        "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
        "        return node\n",
        "\n",
        "    async def acall(\n",
        "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
        "    ) -> List[BaseNode]:\n",
        "        \"\"\"Extract triples from nodes async.\"\"\"\n",
        "        jobs = []\n",
        "        for node in nodes:\n",
        "            jobs.append(self._aextract(node))\n",
        "\n",
        "        return await run_jobs(\n",
        "            jobs,\n",
        "            workers=self.num_workers,\n",
        "            show_progress=show_progress,\n",
        "            desc=\"Extracting paths from text\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwkVpuUas-wK"
      },
      "source": [
        "## GraphRAGStore\n",
        "\n",
        "The `GraphRAGStore` class is an extension of the `SimplePropertyGraphStore `class, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
        "\n",
        "\n",
        "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n",
        "\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "`build_communities():`\n",
        "\n",
        "1. Converts the internal graph representation to a NetworkX graph.\n",
        "\n",
        "2. Applies the hierarchical Leiden algorithm for community detection.\n",
        "\n",
        "3. Collects detailed information about each community.\n",
        "\n",
        "4. Generates summaries for each community.\n",
        "\n",
        "`generate_community_summary(text):`\n",
        "\n",
        "1. Uses LLM to generate a summary of the relationships in a community.\n",
        "2. The summary includes entity names and a synthesis of relationship descriptions.\n",
        "\n",
        "`_create_nx_graph():`\n",
        "\n",
        "1. Converts the internal graph representation to a NetworkX graph for community detection.\n",
        "\n",
        "`_collect_community_info(nx_graph, clusters):`\n",
        "\n",
        "1. Collects detailed information about each node based on its community.\n",
        "2. Creates a string representation of each relationship within a community.\n",
        "\n",
        "`_summarize_communities(community_info):`\n",
        "\n",
        "1. Generates and stores summaries for each community using LLM.\n",
        "\n",
        "`get_community_summaries():`\n",
        "\n",
        "1. Returns the community summaries by building them if not already done."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax==0.5.1"
      ],
      "metadata": {
        "id": "YichxVmBwOJ-",
        "outputId": "db15964a-cf9e-4b21-c59e-3c93a3fe28c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jax==0.5.1\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: jaxlib<=0.5.1,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax==0.5.1) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.5.1) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from jax==0.5.1) (2.0.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.5.1) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax==0.5.1) (1.13.0)\n",
            "Downloading jax-0.5.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.13\n",
            "    Uninstalling jax-0.4.13:\n",
            "      Successfully uninstalled jax-0.4.13\n",
            "Successfully installed jax-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.dtype"
      ],
      "metadata": {
        "id": "LrQesumZ3N_p",
        "outputId": "b7941c56-21e0-4633-8e42-26a0dbe5ddac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.dtype"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cij3x6hks-wK",
        "outputId": "673da60c-e5ed-4fe4-b801-98c224dde502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'dtypes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-43296772aed4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_stores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimplePropertyGraphStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraspologic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhierarchical_leiden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/graspologic/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Licensed under the MIT License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraspologic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraspologic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraspologic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/graspologic/align/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0morthogonal_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrthogonalProcrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mseedless_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeedlessProcrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msign_flips\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSignFlips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/graspologic/align/seedless_procrustes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ot/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# All submodules and packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbregman\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ot/lp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcvx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcvx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbarycenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdmmot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdmmot_monge_1dgrid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmmot_monge_1dgrid_optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# import compiled emd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ot/lp/dmmot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ot/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDISABLE_JAX_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# See PEP 484 & https://github.com/jax-ml/jax/issues/7570\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from jax._src.core import (\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mAbstractToken\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractToken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mAbstractValue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;31m# StringDType to be used in there.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0m_string_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJAXType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StringDType'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mxla_extension_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m311\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m   \u001b[0m_string_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJAXType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringDType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Filter out Cython harmless warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"numpy.dtype size changed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"numpy.ufunc size changed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"numpy.ndarray size changed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'dtypes'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from llama_index.core.graph_stores import SimplePropertyGraphStore\n",
        "import networkx as nx\n",
        "from graspologic.partition import hierarchical_leiden\n",
        "\n",
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "\n",
        "class GraphRAGStore(SimplePropertyGraphStore):\n",
        "    community_summary = {}\n",
        "    max_cluster_size = 5\n",
        "\n",
        "    def generate_community_summary(self, text):\n",
        "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
        "        messages = [\n",
        "            ChatMessage(\n",
        "                role=\"system\",\n",
        "                content=(\n",
        "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
        "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
        "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
        "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
        "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
        "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
        "                ),\n",
        "            ),\n",
        "            ChatMessage(role=\"user\", content=text),\n",
        "        ]\n",
        "        response = OpenAI().chat(messages)\n",
        "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
        "        return clean_response\n",
        "\n",
        "    def build_communities(self):\n",
        "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
        "        nx_graph = self._create_nx_graph()\n",
        "        community_hierarchical_clusters = hierarchical_leiden(\n",
        "            nx_graph, max_cluster_size=self.max_cluster_size\n",
        "        )\n",
        "        community_info = self._collect_community_info(\n",
        "            nx_graph, community_hierarchical_clusters\n",
        "        )\n",
        "        self._summarize_communities(community_info)\n",
        "\n",
        "    def _create_nx_graph(self):\n",
        "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
        "        nx_graph = nx.Graph()\n",
        "        for node in self.graph.nodes.values():\n",
        "            nx_graph.add_node(str(node))\n",
        "        for relation in self.graph.relations.values():\n",
        "            nx_graph.add_edge(\n",
        "                relation.source_id,\n",
        "                relation.target_id,\n",
        "                relationship=relation.label,\n",
        "                description=relation.properties[\"relationship_description\"],\n",
        "            )\n",
        "        return nx_graph\n",
        "\n",
        "    def _collect_community_info(self, nx_graph, clusters):\n",
        "        \"\"\"Collect detailed information for each node based on their community.\"\"\"\n",
        "        community_mapping = {item.node: item.cluster for item in clusters}\n",
        "        community_info = {}\n",
        "        for item in clusters:\n",
        "            cluster_id = item.cluster\n",
        "            node = item.node\n",
        "            if cluster_id not in community_info:\n",
        "                community_info[cluster_id] = []\n",
        "\n",
        "            for neighbor in nx_graph.neighbors(node):\n",
        "                if community_mapping[neighbor] == cluster_id:\n",
        "                    edge_data = nx_graph.get_edge_data(node, neighbor)\n",
        "                    if edge_data:\n",
        "                        detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
        "                        community_info[cluster_id].append(detail)\n",
        "        return community_info\n",
        "\n",
        "    def _summarize_communities(self, community_info):\n",
        "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
        "        for community_id, details in community_info.items():\n",
        "            details_text = (\n",
        "                \"\\n\".join(details) + \".\"\n",
        "            )  # Ensure it ends with a period\n",
        "            self.community_summary[\n",
        "                community_id\n",
        "            ] = self.generate_community_summary(details_text)\n",
        "\n",
        "    def get_community_summaries(self):\n",
        "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
        "        if not self.community_summary:\n",
        "            self.build_communities()\n",
        "        return self.community_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbQ04G-4s-wK"
      },
      "source": [
        "## GraphRAGQueryEngine\n",
        "\n",
        "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
        "\n",
        "**Main Components:**\n",
        "\n",
        "`graph_store:` An instance of GraphRAGStore, which contains the community summaries.\n",
        "`llm:` A Language Model (LLM) used for generating and aggregating answers.\n",
        "\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "`custom_query(query_str: str)`\n",
        "\n",
        "1. This is the main entry point for processing a query. It retrieves community summaries, generates answers from each summary, and then aggregates these answers into a final response.\n",
        "\n",
        "`generate_answer_from_summary(community_summary, query):`\n",
        "\n",
        "1. Generates an answer for the query based on a single community summary.\n",
        "Uses the LLM to interpret the community summary in the context of the query.\n",
        "\n",
        "`aggregate_answers(community_answers):`\n",
        "\n",
        "1. Combines individual answers from different communities into a coherent final response.\n",
        "2. Uses the LLM to synthesize multiple perspectives into a single, concise answer.\n",
        "\n",
        "\n",
        "**Query Processing Flow:**\n",
        "\n",
        "1. Retrieve community summaries from the graph store.\n",
        "2. For each community summary, generate a specific answer to the query.\n",
        "3. Aggregate all community-specific answers into a final, coherent response.\n",
        "\n",
        "\n",
        "**Example usage:**\n",
        "\n",
        "```\n",
        "query_engine = GraphRAGQueryEngine(graph_store=graph_store, llm=llm)\n",
        "\n",
        "response = query_engine.query(\"query\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPlSQCl1s-wK"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import CustomQueryEngine\n",
        "from llama_index.core.llms import LLM\n",
        "\n",
        "\n",
        "class GraphRAGQueryEngine(CustomQueryEngine):\n",
        "    graph_store: GraphRAGStore\n",
        "    llm: LLM\n",
        "\n",
        "    def custom_query(self, query_str: str) -> str:\n",
        "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
        "        community_summaries = self.graph_store.get_community_summaries()\n",
        "        community_answers = [\n",
        "            self.generate_answer_from_summary(community_summary, query_str)\n",
        "            for _, community_summary in community_summaries.items()\n",
        "        ]\n",
        "\n",
        "        final_answer = self.aggregate_answers(community_answers)\n",
        "        return final_answer\n",
        "\n",
        "    def generate_answer_from_summary(self, community_summary, query):\n",
        "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
        "        prompt = (\n",
        "            f\"Given the community summary: {community_summary}, \"\n",
        "            f\"how would you answer the following query? Query: {query}\"\n",
        "        )\n",
        "        messages = [\n",
        "            ChatMessage(role=\"system\", content=prompt),\n",
        "            ChatMessage(\n",
        "                role=\"user\",\n",
        "                content=\"I need an answer based on the above information.\",\n",
        "            ),\n",
        "        ]\n",
        "        response = self.llm.chat(messages)\n",
        "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
        "        return cleaned_response\n",
        "\n",
        "    def aggregate_answers(self, community_answers):\n",
        "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
        "        # intermediate_text = \" \".join(community_answers)\n",
        "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
        "        messages = [\n",
        "            ChatMessage(role=\"system\", content=prompt),\n",
        "            ChatMessage(\n",
        "                role=\"user\",\n",
        "                content=f\"Intermediate answers: {community_answers}\",\n",
        "            ),\n",
        "        ]\n",
        "        final_response = self.llm.chat(messages)\n",
        "        cleaned_final_response = re.sub(\n",
        "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
        "        ).strip()\n",
        "        return cleaned_final_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7k094DKs-wL"
      },
      "source": [
        "##  Build End to End GraphRAG Pipeline\n",
        "\n",
        "Now that we have defined all the necessary components, let’s construct the GraphRAG pipeline:\n",
        "\n",
        "1. Create nodes/chunks from the text.\n",
        "2. Build a PropertyGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`.\n",
        "3. Construct communities and generate a summary for each community using the graph built above.\n",
        "4. Create a `GraphRAGQueryEngine` and begin querying."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmpc0EHYs-wL"
      },
      "source": [
        "### Create nodes/ chunks from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeXlM_Ats-wL"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=20,\n",
        ")\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXl8eu0zs-wL",
        "outputId": "dbe3ac09-04e9-4b77-f82e-80cf21647dfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dsj2U-Hs-wL"
      },
      "source": [
        "### Build ProperGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJoA5PlBs-wL"
      },
      "outputs": [],
      "source": [
        "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
        "-Goal-\n",
        "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
        "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
        "\n",
        "-Steps-\n",
        "1. Identify all entities. For each identified entity, extract the following information:\n",
        "- entity_name: Name of the entity, capitalized\n",
        "- entity_type: Type of the entity\n",
        "- entity_description: Comprehensive description of the entity's attributes and activities\n",
        "\n",
        "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
        "For each pair of related entities, extract the following information:\n",
        "- source_entity: name of the source entity, as identified in step 1\n",
        "- target_entity: name of the target entity, as identified in step 1\n",
        "- relation: relationship between source_entity and target_entity\n",
        "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
        "\n",
        "3. Output Formatting:\n",
        "- Return the result in valid JSON format with two keys: 'entities' (list of entity objects) and 'relationships' (list of relationship objects).\n",
        "- Exclude any text outside the JSON structure (e.g., no explanations or comments).\n",
        "- If no entities or relationships are identified, return empty lists: { \"entities\": [], \"relationships\": [] }.\n",
        "\n",
        "-An Output Example-\n",
        "{\n",
        "  \"entities\": [\n",
        "    {\n",
        "      \"entity_name\": \"Albert Einstein\",\n",
        "      \"entity_type\": \"Person\",\n",
        "      \"entity_description\": \"Albert Einstein was a theoretical physicist who developed the theory of relativity and made significant contributions to physics.\"\n",
        "    },\n",
        "    {\n",
        "      \"entity_name\": \"Theory of Relativity\",\n",
        "      \"entity_type\": \"Scientific Theory\",\n",
        "      \"entity_description\": \"A scientific theory developed by Albert Einstein, describing the laws of physics in relation to observers in different frames of reference.\"\n",
        "    },\n",
        "    {\n",
        "      \"entity_name\": \"Nobel Prize in Physics\",\n",
        "      \"entity_type\": \"Award\",\n",
        "      \"entity_description\": \"A prestigious international award in the field of physics, awarded annually by the Royal Swedish Academy of Sciences.\"\n",
        "    }\n",
        "  ],\n",
        "  \"relationships\": [\n",
        "    {\n",
        "      \"source_entity\": \"Albert Einstein\",\n",
        "      \"target_entity\": \"Theory of Relativity\",\n",
        "      \"relation\": \"developed\",\n",
        "      \"relationship_description\": \"Albert Einstein is the developer of the theory of relativity.\"\n",
        "    },\n",
        "    {\n",
        "      \"source_entity\": \"Albert Einstein\",\n",
        "      \"target_entity\": \"Nobel Prize in Physics\",\n",
        "      \"relation\": \"won\",\n",
        "      \"relationship_description\": \"Albert Einstein won the Nobel Prize in Physics in 1921.\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "-Real Data-\n",
        "######################\n",
        "text: {text}\n",
        "######################\n",
        "output:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZY_S0Pxs-wL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def parse_fn(response_str: str) -> Any:\n",
        "    json_pattern = r\"\\{.*\\}\"\n",
        "    match = re.search(json_pattern, response_str, re.DOTALL)\n",
        "    entities = []\n",
        "    relationships = []\n",
        "    if not match:\n",
        "        return entities, relationships\n",
        "    json_str = match.group(0)\n",
        "    try:\n",
        "        data = json.loads(json_str)\n",
        "        entities = [\n",
        "            (\n",
        "                entity[\"entity_name\"],\n",
        "                entity[\"entity_type\"],\n",
        "                entity[\"entity_description\"],\n",
        "            )\n",
        "            for entity in data.get(\"entities\", [])\n",
        "        ]\n",
        "        relationships = [\n",
        "            (\n",
        "                relation[\"source_entity\"],\n",
        "                relation[\"target_entity\"],\n",
        "                relation[\"relation\"],\n",
        "                relation[\"relationship_description\"],\n",
        "            )\n",
        "            for relation in data.get(\"relationships\", [])\n",
        "        ]\n",
        "        return entities, relationships\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error parsing JSON:\", e)\n",
        "        return entities, relationships\n",
        "\n",
        "\n",
        "kg_extractor = GraphRAGExtractor(\n",
        "    llm=llm,\n",
        "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
        "    max_paths_per_chunk=2,\n",
        "    parse_fn=parse_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4moeOfcls-wL",
        "outputId": "fb196c3a-d1ce-492a-b00e-035774a44025"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting paths from text: 100%|██████████| 50/50 [04:30<00:00,  5.41s/it]\n",
            "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
            "Generating embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import PropertyGraphIndex\n",
        "\n",
        "index = PropertyGraphIndex(\n",
        "    nodes=nodes,\n",
        "    property_graph_store=GraphRAGStore(),\n",
        "    kg_extractors=[kg_extractor],\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwrbTC8xs-wL",
        "outputId": "957a306b-365d-4d9c-d9c6-ed6e3095c64a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EntityNode(label='entity', embedding=None, properties={'relationship_description': 'Gett Taxi is a competitor of Uber in the Israeli taxi market.', 'triplet_source_id': 'e4f765e3-fdfd-48d0-92a9-36f75b5865aa'}, name='Competition')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.nodes.values())[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU7y9V0As-wL",
        "outputId": "42263666-7493-4117-d950-d6e5c17a5817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Relation(label='O&G sector', source_id='Chevron', target_id='Operates in', properties={'relationship_description': 'Chevron operates in the O&G sector, as evidenced by the text mentioning that it is a company in this industry.', 'triplet_source_id': '6a28dc67-0dc0-486f-8dd6-70a3502f1c8e'})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.relations.values())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32GagO3Is-wL",
        "outputId": "a89ae530-feab-4140-d931-99791de36e36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Chevron operates in the O&G sector, as evidenced by the text mentioning that it is a company in this industry.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.relations.values())[0].properties[\n",
        "    \"relationship_description\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5YtVD8Ts-wM"
      },
      "source": [
        "### Build communities\n",
        "\n",
        "This will create communities and summary for each community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9o_SHGFs-wM"
      },
      "outputs": [],
      "source": [
        "index.property_graph_store.build_communities()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LhhsK13s-wM"
      },
      "source": [
        "### Create QueryEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr0Tee6Ns-wM"
      },
      "outputs": [],
      "source": [
        "query_engine = GraphRAGQueryEngine(\n",
        "    graph_store=index.property_graph_store, llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-wKgz74s-wM"
      },
      "source": [
        "### Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q2mERLLs-wM",
        "outputId": "4cb1d521-848a-46bd-d62b-cd965bd51467"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The document discusses various news topics across different sectors. In the business sector, it mentions FirstEnergy being a publicly traded company on the New York Stock Exchange and State Street Corporation being listed on the NYSE. It also discusses Coinbase Global Inc.'s repurchase of $64.5 million worth of 0.50% convertible senior notes and the closure of the startup Protonn. In the political sphere, it highlights a theatrical act performed by Sinn Féin TD John Brady during a debate on retained firefighters. In the tech industry, it discusses the European Commission's actions against ZTE Corp. and TikTok Inc. due to security concerns. In the sports sector, it mentions Manchester United's interest in Harry Kane, the transfer of Jude Bellingham from Borussia Dortmund to Real Madrid, and the negotiation process for Maliek Collins' contract extension with the Houston Texans. In the music industry, it discusses the acquisition of The Hollies' recording catalog by BMG and the distribution pact between ADA Worldwide and Rostrum Records. In the hospitality sector, it mentions the partnership between Supplier.io and Hyatt Hotels. In the energy sector, it discusses the partnership between GE Vernova and Amplus Solar. In the gaming industry, it discusses the creation of the unannounced game \"Star Ocean: The Second Story R\" by Square Enix. In the automotive industry, it mentions the upcoming launch of the Hyundai Exter in India and Stellantis' plans to shut down the Belvidere Assembly Plant. In the airline industry, it discusses Deutsche Bank's decision to upgrade Allegiant Travel's status from Hold to Buy. In the football sector, it discusses the rejected bids made by Arsenal for Rice and the rejected bid received by Chelsea for Mason Mount. In the space industry, it mentions MDA Ltd.'s participation in the Jefferies Virtual Space Summit. In the transportation industry, it discusses Uber's strategic decision to exit the Israeli market and the emergence of Yango as a key player in the Israeli taxi market."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"What are the main news discussed in the document?\"\n",
        ")\n",
        "display(Markdown(f\"{response.response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsIc1Pa1s-wM",
        "outputId": "483f318a-95d9-4b34-fe04-92a38b266724"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The recent news related to the financial sector includes Morgan Stanley hiring Thomas Christl to co-head its coverage of consumer and retail clients in Europe. KeyBank has expanded its presence in the Western U.S. by opening a new branch in American Fork and donated $10,000 to the Five.12 Foundation. BMG has acquired the recording catalog of The Hollies, and Matt Pincus led a $15 million pre-growth round of investment for Soundtrack Your Brand. Hyatt Hotels and Supplier.io have been honored with the Supply & Demand Chain Executive 2023 Top Supply Chain Projects award. Bank of America Corp. reported a decline in uninsured deposits, while JPMorgan Chase & Co. reported a 1.9% increase in uninsured deposits. Coinbase Global Inc. repurchased $64.5 million worth of 0.50% convertible senior notes and also decided to repurchase its 0.50% Convertible Senior Notes due 2026 for approximately $45.5 million. Deutsche Bank upgraded Allegiant Travel's status from Hold to Buy and increased the price target to $145. Lastly, Tesla Inc.'s stock performance was analyzed by Ihor Dusaniwsky, a managing director at S3 Partners, and the company formed a significant partnership with General Motors Co. in the electric vehicle industry."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = query_engine.query(\"What are news related to financial sector?\")\n",
        "display(Markdown(f\"{response.response}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap75_WnJs-wM"
      },
      "source": [
        "## Future Work:\n",
        "\n",
        "This cookbook is an approximate implementation of GraphRAG. In future cookbooks, we plan to extend it as follows:\n",
        "\n",
        "1. Implement retrieval using entity description embeddings.\n",
        "2. Integrate with Neo4JPropertyGraphStore.\n",
        "3. Calculate a helpfulness score for each answer generated from the community summaries and filter out answers where the helpfulness score is zero.\n",
        "4. Perform entity disambiguation to remove duplicate entities.\n",
        "5. Implement claims or covariate information extraction, Local Search and Global Search techniques."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "llamaindex",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}